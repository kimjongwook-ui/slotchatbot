
# app.py â€” Kanana ìŠ¬ë¡¯ ê²€ìƒ‰ (HF Spaces, Gradio 4.44.0)
# ë²„ì „: ìŠ¬ë¡¯ì„œì¹˜ì™„ì„±1.3-external (ì™¸ë¶€ ìŠ¬ë¡¯ rgs/sng + 2nd CSV ì§€ì›)
import os, io, re, time, requests
import pandas as pd
import gradio as gr

# ====== ê³ ì • ì„¤ì • ======
OWNER, REPO, BRANCH = "kimjongwook-ui", "slotchatbot", "data"
CSV_PATH_MAIN      = "game_info.csv"             # ë‚´ë¶€ ìŠ¬ë¡¯(ê¸°ì¡´)
CSV_PATH_EXTERNAL  = "external_game_info.csv"    # ì™¸ë¶€ ìŠ¬ë¡¯(rgs/sng)
CSV_URL_MAIN      = f"https://raw.githubusercontent.com/{OWNER}/{REPO}/{BRANCH}/{CSV_PATH_MAIN}"
CSV_URL_EXTERNAL  = f"https://raw.githubusercontent.com/{OWNER}/{REPO}/{BRANCH}/{CSV_PATH_EXTERNAL}"
TTL_SEC = 600  # CSV ìºì‹œ 10ë¶„

# (ì„ íƒ) ë¡œì»¬ ìš°ì„  í…ŒìŠ¤íŠ¸ ê²½ë¡œ. ì§€ì •ì‹œ ë¡œì»¬ íŒŒì¼ ì‚¬ìš© í›„, ì—†ìœ¼ë©´ GitHub URL ì‚¬ìš©.
CSV_LOCAL_MAIN     = os.getenv("CSV_LOCAL_MAIN")     # ì˜ˆ: /data/game_info.csv
CSV_LOCAL_EXTERNAL = os.getenv("CSV_LOCAL_EXTERNAL") # ì˜ˆ: /data/external_game_info.csv

# ====== ë‚´ë¶€ ìºì‹œ ======
_df_cache_main = None
_df_cache_ext  = None
_last_loaded_main = 0.0
_last_loaded_ext  = 0.0

# ====== CSS: íˆìŠ¤í† ë¦¬(ë¡œê·¸) ì°½ì„ ë“œë˜ê·¸/ìŠ¤í¬ë¡¤ ê°€ëŠ¥ ë°•ìŠ¤ë¡œ ê³ ì • ======
CUSTOM_CSS = """
#history-box {
  max-height: 360px;
  min-height: 160px;
  overflow: auto;
  border: 1px solid #e5e7eb;
  border-radius: 8px;
  padding: 8px 10px;
  resize: vertical; /* ë“œë˜ê·¸ë¡œ ë†’ì´ ì¡°ì ˆ */
  background: #fafafa;
}
"""

# ====== ìœ í‹¸ ======
def _first_number(s):
    """'95.6%', '25 Lines', '1,024' â†’ 95.6 / 25 / 1024"""
    if s is None or (isinstance(s, float) and pd.isna(s)):
        return None
    t = str(s).replace(",", "").replace("%", "")
    m = re.search(r"[-+]?\d*\.?\d+", t)
    return float(m.group(0)) if m else None

def _num_series(series: pd.Series) -> pd.Series:
    return series.astype(str) \
        .str.replace(",", "", regex=False) \
        .str.replace("%", "", regex=False) \
        .str.extract(r"([-+]?\d*\.?\d+)")[0] \
        .astype(float)

def _norm_text(s: str) -> str:
    """ë¼ì¸ ë¬¸ìì—´ ì •ê·œí™”: '25 Lines'â†’'25', 'Land & Win'â†’'land&win' ë“±"""
    if s is None or (isinstance(s, float) and pd.isna(s)):
        return ""
    t = str(s).lower()
    t = t.replace(" ", "")
    t = t.replace("and", "&").replace("+", "&")
    t = t.replace("lines", "").replace("line", "").replace("ë¼ì¸", "")
    t = t.replace("ways", "").replace("way", "").replace("ì›¨ì´", "")
    t = t.replace("landwin", "land&win")
    return t

def find_col(df: pd.DataFrame, cands):
    cols = {c.lower(): c for c in df.columns}
    for x in cands:
        if x and x.lower() in cols:
            return cols[x.lower()]
    for c in df.columns:
        lc = c.lower()
        if any(x.lower() in lc for x in cands if x):
            return c
    return None

def find_multi_cols(df: pd.DataFrame, base_keywords, max_n=4):
    """theme1~4, feature1~4 ê°™ì€ ê³„ì—´ ì¹¼ëŸ¼ ì¶”ì¶œ"""
    names = []
    for n in range(1, max_n+1):
        cand = find_col(df, [f"{k}{n}" for k in base_keywords])
        if cand and cand not in names:
            names.append(cand)
    for k in base_keywords:
        cand = find_col(df, [k])
        if cand and cand not in names:
            names.append(cand)
    for c in df.columns:
        lc = c.lower()
        if any(k in lc for k in base_keywords) and c not in names:
            names.append(c)
        if len(names) >= max_n:
            break
    return names[:max_n]

def detect_schema_main(df: pd.DataFrame):
    # ë‚´ë¶€ ìŠ¬ë¡¯ ìŠ¤í‚¤ë§ˆ (ê¸°ì¡´)
    return {
        "id":        find_col(df, ["game_id","slot_id","id","gameid","ê²Œì„id","ê²Œì„_id"]),
        "name":      find_col(df, ["title","name","ê²Œì„ëª…","slot","game"]),
        "type":      find_col(df, ["type","slot_type","ê²Œì„íƒ€ì…","íƒ€ì…"]),  # lines/ways
        "overall_rtp": find_col(df, ["rtp","overall_rtp","total_rtp","ì „ì²´ rtp"]),
        "base_rtp":    find_col(df, ["base_rtp","ë² ì´ìŠ¤ rtp"]),
        "free_rtp":    find_col(df, ["free_rtp","í”„ë¦¬ rtp","freespin rtp"]),
        "volatility":  find_col(df, ["volatility","variance","í¸ì°¨","ë³¼ë¼"]),
        "hit_rate":    find_col(df, ["hit_rate","hit rate","íˆíŠ¸","íˆíŠ¸ìœ¨","ìŠ¹ë¥ ","í™•ë¥ "]),
        "lines":       find_col(df, ["line","lines","ë¼ì¸"]),
        "ways":        find_col(df, ["way","ways","ì›¨ì´"]),
        "size":        find_col(df, ["size","grid","ë¦´í–‰","ë¦´xí–‰","ë¦´ìˆ˜xí–‰ìˆ˜"]),
        "reels":       find_col(df, ["reels","reel","ë¦´","columns"]),
        "rows":        find_col(df, ["rows","row","í–‰"]),
        "themes":      find_multi_cols(df, ["theme","í…Œë§ˆ"], max_n=4),
        "features":    find_multi_cols(df, ["feature","features","í”¼ì³","íŠ¹ì§•"], max_n=4),
        "maker":       find_col(df, ["maker","provider","ì œì‘ì‚¬","í¼ë¸”ë¦¬ì…”"]),
    }

def detect_schema_ext(df: pd.DataFrame):
    # ì™¸ë¶€ ìŠ¬ë¡¯ ìŠ¤í‚¤ë§ˆ (external_game_info.csv)
    return {
        "id":        find_col(df, ["game_id","slot_id","id","gameid","ê²Œì„id","ê²Œì„_id"]),
        "name":      find_col(df, ["title","name","ê²Œì„ëª…","slot","game"]),
        "ext_type":  find_col(df, ["rgs","sng","type","ì™¸ë¶€íƒ€ì…","ì™¸ë¶€ íƒ€ì…"]),  # rgs/sng
        "maker":     find_col(df, ["maker","provider","íšŒì‚¬","ì œì‘ì‚¬","í¼ë¸”ë¦¬ì…”"]),
        "size":      find_col(df, ["size","grid","ë¦´í–‰","ë¦´xí–‰","ë¦´ìˆ˜xí–‰ìˆ˜"]),
        "lines":     find_col(df, ["line","lines","ë¼ì¸"]),
        "themes":    find_multi_cols(df, ["theme","í…Œë§ˆ"], max_n=4),
        "features":  find_multi_cols(df, ["feature","features","í”¼ì³","íŠ¹ì§•"], max_n=4),
        # ì°¸ê³ : ì™¸ë¶€ íŒŒì¼ì€ rtp/hit/volatilityê°€ ì—†ì„ ìˆ˜ ìˆìŒ
    }

# ====== ë°ì´í„° ë¡œë“œ/ì¤€ë¹„ ======
def _read_csv(url: str, local_path: str|None = None):
    if local_path and os.path.exists(local_path):
        return pd.read_csv(local_path)
    r = requests.get(url, timeout=20)
    r.raise_for_status()
    try:
        return pd.read_csv(io.StringIO(r.text))
    except Exception:
        return pd.read_csv(io.StringIO(r.text), encoding="utf-8-sig")

def load_df(source: str = "main", force: bool = False) -> pd.DataFrame:
    global _df_cache_main, _df_cache_ext, _last_loaded_main, _last_loaded_ext
    now = time.time()
    if source == "main":
        if not force and _df_cache_main is not None and (now - _last_loaded_main) < TTL_SEC:
            return _df_cache_main
        df = _read_csv(CSV_URL_MAIN, CSV_LOCAL_MAIN)
        if df.empty or len(df.columns) == 0:
            raise RuntimeError("ë©”ì¸ CSVë¥¼ ì½ì—ˆì§€ë§Œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        _df_cache_main, _last_loaded_main = df, now
        return df
    else:
        if not force and _df_cache_ext is not None and (now - _last_loaded_ext) < TTL_SEC:
            return _df_cache_ext
        df = _read_csv(CSV_URL_EXTERNAL, CSV_LOCAL_EXTERNAL)
        if df.empty or len(df.columns) == 0:
            raise RuntimeError("ì™¸ë¶€ CSVë¥¼ ì½ì—ˆì§€ë§Œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        _df_cache_ext, _last_loaded_ext = df, now
        return df

def prepare_df_main(df_raw: pd.DataFrame):
    df = df_raw.copy()
    S = detect_schema_main(df)

    # ìˆ«ì íŒŒìƒ
    rtp_col = S["overall_rtp"] or S["base_rtp"] or S["free_rtp"]
    df["_rtp"]   = _num_series(df[rtp_col]) if rtp_col in df.columns else pd.NA
    df["_vola"]  = _num_series(df[S["volatility"]]) if S["volatility"] in df.columns else pd.NA
    df["_hit"]   = _num_series(df[S["hit_rate"]])   if S["hit_rate"] in df.columns   else pd.NA
    df["_lines"] = df[S["lines"]].apply(_first_number) if S["lines"] in df.columns else pd.NA
    df["_ways"]  = df[S["ways"]].apply(_first_number)  if S["ways"]  in df.columns else pd.NA

    # í¼ì„¼íŠ¸ ë‹¨ìœ„ ìë™ ë³´ì •
    for col in ["_rtp", "_hit"]:
        if col in df.columns:
            s = pd.to_numeric(df[col], errors="coerce")
            if s.dropna().size > 0 and (s.dropna() <= 1.5).mean() > 0.8:
                df[col] = s * 100.0

    # ë¼ì¸ í…ìŠ¤íŠ¸ ì •ê·œí™”(ëœë“œì•¤ìœˆ ì¸ì‹ìš©)
    if S["lines"] in df.columns:
        df["_lines_txt"] = df[S["lines"]].apply(_norm_text)
    else:
        df["_lines_txt"] = ""

    # ì‚¬ì´ì¦ˆ ê·¸ë¦¬ë“œ í‘œì¤€í™”
    if S["size"] in df.columns:
        df["_grid"] = (
            df[S["size"]].astype(str)
            .str.extract(r"(\d+\s*[xXÃ—]\s*\d+)")[0]
            .str.replace(" ", "", regex=False).str.lower()
        )
    elif S["reels"] in df.columns and S["rows"] in df.columns:
        df["_grid"] = (
            df[S["reels"]].astype(str).str.extract(r"(\d+)")[0]
            + "x" +
            df[S["rows"]].astype(str).str.extract(r"(\d+)")[0]
        ).str.lower()
    else:
        df["_grid"] = pd.NA

    return df, S

def prepare_df_ext(df_raw: pd.DataFrame):
    df = df_raw.copy()
    S = detect_schema_ext(df)

    # ìˆ«ì íŒŒìƒ (extì—ëŠ” rtp/hit/volaê°€ ì—†ì„ ìˆ˜ ìˆìŒ)
    if S["lines"] in df.columns:
        df["_lines"] = df[S["lines"]].apply(_first_number)
        df["_lines_txt"] = df[S["lines"]].apply(_norm_text)
    else:
        df["_lines"] = pd.NA
        df["_lines_txt"] = ""

    if S["size"] in df.columns:
        df["_grid"] = (
            df[S["size"]].astype(str)
            .str.extract(r"(\d+\s*[xXÃ—]\s*\d+)")[0]
            .str.replace(" ", "", regex=False).str.lower()
        )
    else:
        df["_grid"] = pd.NA

    # ext_type ì •ê·œí™”(rgs/sng)
    if S["ext_type"] in df.columns:
        df["_ext_type"] = df[S["ext_type"]].astype(str).str.lower().str.extract(r"(rgs|sng)")[0]
    else:
        df["_ext_type"] = pd.NA

    return df, S

# ====== íŒŒì„œ ======
NUM   = r"(?P<num>\d+(?:\.\d+)?)"
RANGE = r"(?P<n1>\d+(?:\.\d+)?)[\s]*(?:~|-|to|â€“|â€”|ê¹Œì§€)\s*(?P<n2>\d+(?:\.\d+)?)"
SIZEP = r"(?P<r>\d+)\s*[xXÃ—]\s*(?P<c>\d+)"

FIELD_ALIASES = {
    "rtp":        [r"\brtp\b", r"\boverall\s*rtp\b", r"\btotal\s*rtp\b", r"ì „ì²´\s*rtp"],
    "volatility": [r"í¸ì°¨", r"\bvolatility\b", r"\bvariance\b", r"ë³¼ë¼"],
    "hit_rate":   [r"íˆíŠ¸(ìœ¨)?", r"hit\s*rate", r"ìŠ¹ë¥ ", r"í™•ë¥ "],
    "lines":      [r"ë¼ì¸", r"\blines?\b"],
    "ways":       [r"ì›¨ì´",  r"\bways?\b"],
}

CMP_WORD = {"ì´ìƒ": ">=", "ì´í•˜": "<=", "ì´ˆê³¼": ">", "ë¯¸ë§Œ": "<", "ê°™ìŒ": "=="}
LANDWIN_WORDS = ["land&win","land and win","ëœë“œì•¤ìœˆ","ëœì•¤ìœˆ","hold&win","hold and win"]

# ì™¸ë¶€ ìŠ¬ë¡¯ ì¸ì‹ìš©
EXTERNAL_SYNONYMS = [
    "ì™¸ë¶€", "ì™¸ë¶€ìŠ¬ë¡¯", "ì™¸ë¶€ ìŠ¬ë¡¯", "ì™¸ë¶€ íƒ€ì…", "ì™¸ë¶€íƒ€ì…",
    "íƒ€ì‚¬", "íƒ€ íšŒì‚¬", "íƒ€íšŒì‚¬", "ì™¸ ìŠ¬ë¡¯", "ì™¸ íƒ€ì…"
]

STOPWORDS = set("""
ì´ìƒ ì´í•˜ ì´ˆê³¼ ë¯¸ë§Œ ë¶€í„° ê¹Œì§€ ì‚¬ì´ ê·¸ë¦¬ê³  ì´ë©° ì´ê³  ì€ ëŠ” ì´ ê°€ ì„ ë¥¼ ì— ì˜ ë„ ë§Œ ì™€ ê³¼ ê³¼ì˜ ë° ì—ì„œ ìœ¼ë¡œ ë¡œ ë„ëŠ” ëŠ”ë° í•œë° 
and & between to the a of slot slots ìŠ¬ë¡¯ ì°¾ì•„ì¤˜ ì°¾ì•„ ì¤˜ ì°¾ì•„ ì•Œë ¤ì¤˜ ì•Œë ¤ ì¤˜ íƒ€ì… type size ì‚¬ì´ì¦ˆ
rtp volatility variance í¸ì°¨ ë³¼ë¼ íˆíŠ¸ íˆíŠ¸ìœ¨ ìŠ¹ë¥  í™•ë¥  line lines ë¼ì¸ way ways ì›¨ì´ land&win ëœë“œì•¤ìœˆ
rgs sng ì™¸ë¶€ ì™¸ë¶€ìŠ¬ë¡¯ ì™¸ë¶€íƒ€ì… ì™¸ë¶€ íƒ€ì… íƒ€ì‚¬ íƒ€ íšŒì‚¬ íƒ€íšŒì‚¬ ì™¸ ìŠ¬ë¡¯ ì™¸ íƒ€ì…
""".split())

def _normalize_query_text(q: str) -> str:
    q = q.strip()
    q = q.replace("ì½”ì¸ ê·¸ë©", "ì½”ì¸ê·¸ë©").replace("coin grab", "coingrab")
    return q

def _extract_numeric(field_key, text):
    res = []
    aliases = FIELD_ALIASES.get(field_key, [])
    # 1) ë²”ìœ„
    rp = rf"({'|'.join(aliases)})\s*(?:{RANGE})"
    for m in re.finditer(rp, text, flags=re.I):
        a, b = float(m.group("n1")), float(m.group("n2"))
        res.append(("between", (min(a,b), max(a,b))))
    if res: return res
    # 2-a) ë¹„êµ/ê¸°í˜¸ (ì—°ì‚°ìâ†’ìˆ«ì)
    cw = "|".join(CMP_WORD.keys()); ops = r"[<>]=?|=="
    cp1 = rf"({'|'.join(aliases)})\s*(?:({ops}|{cw}))\s*{NUM}%?"
    for m in re.finditer(cp1, text, flags=re.I):
        op = CMP_WORD.get(m.group(2), m.group(2))
        val = float(m.group("num"))
        res.append((op, val))
    if res: return res
    # 2-b) ë¹„êµ/ê¸°í˜¸ (ìˆ«ìâ†’ì—°ì‚°ì)
    cp2 = rf"({'|'.join(aliases)})\s*{NUM}%?\s*(?:({ops}|{cw}))"
    for m in re.finditer(cp2, text, flags=re.I):
        op = CMP_WORD.get(m.group(2), m.group(2))
        val = float(m.group("num"))
        res.append((op, val))
    if res: return res
    # 3) ë‹¨ì¼ê°’ â†’ [v, v+0.5]
    sp = rf"({'|'.join(aliases)})\s*{NUM}%?"
    for m in re.finditer(sp, text, flags=re.I):
        v = float(m.group("num"))
        res.append(("between", (v, v+0.5)))
    return res

def parse_query(q: str):
    q = _normalize_query_text(q)
    low = q.lower()
    out = {
        "size": None, "rtp": [], "volatility": [], "hit_rate": [],
        "lines": [], "ways": [], "keywords": [], "landwin": False,
        "external_only": False, "ext_type": None  # rgs/sng
    }
    if not q: return out

    # ì™¸ë¶€ ìŠ¬ë¡¯ ë¼ìš°íŒ…
    if any(s in low for s in [s.lower() for s in EXTERNAL_SYNONYMS]):
        out["external_only"] = True
    # rgs/sng íƒ€ì… ì¶”ì¶œ
    if re.search(r"\brgs\b", low): out["ext_type"] = "rgs"
    if re.search(r"\bsng\b", low): out["ext_type"] = "sng"

    # ì‚¬ì´ì¦ˆ 5x3
    m = re.search(SIZEP, q, flags=re.I)
    if m:
        out["size"] = (int(m.group("r")), int(m.group("c")))

    # ìˆ˜ì¹˜ ì¡°ê±´(ë‚´ë¶€ ìŠ¬ë¡¯ì—ë§Œ ì‚¬ìš©ë¨)
    out["rtp"]        = _extract_numeric("rtp", q)
    out["volatility"] = _extract_numeric("volatility", q)
    out["hit_rate"]   = _extract_numeric("hit_rate", q)

    # 25 ë¼ì¸ / 243 ways
    m = re.search(r"(?<!\d)(\d+(?:\.\d+)?)\s*(lines?|ë¼ì¸)\b", q, flags=re.I)
    if m: out["lines"] = [("==", float(m.group(1)))]
    m = re.search(r"(?<!\d)(\d+(?:\.\d+)?)\s*(ways?|ì›¨ì´)\b", q, flags=re.I)
    if m: out["ways"]  = [("==", float(m.group(1)))]

    # ëœë“œì•¤ìœˆ
    if any(w in low for w in [w.lower() for w in LANDWIN_WORDS]):
        out["landwin"] = True

    # í‚¤ì›Œë“œ (í•„ë“œëª…/ë¶ˆìš©ì–´/êµ¬ë‘ì  ì œê±°)
    cleaned = re.sub(SIZEP, " ", q, flags=re.I)
    cleaned = re.sub(r"\d+(\.\d+)?\s*(%|ë¼ì¸|ì›¨ì´)?", " ", cleaned)
    cleaned = re.sub(r"[><=~\-:]+", " ", cleaned)
    cleaned = cleaned.replace(",", " ").replace("/", " ").replace("|", " ").replace("(", " ").replace(")", " ")
    toks = [t.strip().lower() for t in re.split(r"\s+", cleaned) if t.strip()]
    toks = [re.sub(r"^\W+|\W+$", "", t) for t in toks]  # ì–‘ë êµ¬ë‘ì  ì œê±°
    toks = [t for t in toks if t and t not in STOPWORDS]
    out["keywords"] = toks
    return out

# ====== í•„í„° ======
def apply_numeric(df: pd.DataFrame, series_name: str, clauses):
    if not clauses or series_name not in df.columns:
        return pd.Series(True, index=df.index)
    s = pd.to_numeric(df[series_name], errors="coerce")
    m = pd.Series(True, index=df.index)
    for op, val in clauses:
        if op == "between":
            a, b = val
            m &= (s >= a) & (s <= b)
        elif op == ">=": m &= (s >= val)
        elif op == "<=": m &= (s <= val)
        elif op == ">":  m &= (s >  val)
        elif op == "<":  m &= (s <  val)
        elif op == "==": m &= (s == val)
    return m

def filter_size(df: pd.DataFrame, size_tuple):
    if not size_tuple: return pd.Series(True, index=df.index)
    r, c = size_tuple
    return df["_grid"].astype(str).str.fullmatch(fr"{r}[xXÃ—]{c}", case=False, na=False)

def keyword_mask_text(df: pd.DataFrame, text_cols, toks):
    if not toks:
        return pd.Series(True, index=df.index)
    m = pd.Series(True, index=df.index)
    # í‚¤ì›Œë“œ AND
    for t in toks:
        tmask = pd.Series(False, index=df.index)
        for c in text_cols:
            tmask |= df[c].astype(str).str.contains(re.escape(t), case=False, na=False)
        m &= tmask
    return m

# ====== ê²°ê³¼ ì»¬ëŸ¼ ì„ íƒ ======
def build_display_main(df: pd.DataFrame, S, message: str, q=None):
    idcol   = S["id"] or S["name"]
    namecol = S["name"]
    typecol = S["type"]

    rtp_col = S["overall_rtp"] or S["base_rtp"] or S["free_rtp"]
    vola_col= S["volatility"]
    hit_col = S["hit_rate"]
    line_col= S["lines"]
    ways_col= S["ways"]
    size_col= S["size"]

    themes = [c for c in (S.get("themes") or []) if c in df.columns]
    feats  = [c for c in (S.get("features") or []) if c in df.columns]

    msg_l = (message or "").lower()

    wants_rtp   = ("rtp" in msg_l) or (q and q.get("rtp"))
    wants_hit   = (re.search(r"(íˆíŠ¸|hit)", message or "", flags=re.I) is not None) or (q and q.get("hit_rate"))
    wants_vol   = (re.search(r"(í¸ì°¨|volatility|variance|ë³¼ë¼)", message or "", flags=re.I) is not None) or (q and q.get("volatility"))
    wants_lines = (re.search(r"(ë¼ì¸|lines?|land&win|ëœë“œì•¤ìœˆ)", message or "", flags=re.I) is not None) or (q and q.get("lines"))
    wants_size  = ("ì‚¬ì´ì¦ˆ" in (message or "")) or (re.search(SIZEP, message or "") is not None) or (q and q.get("size"))
    wants_theme = ("í…Œë§ˆ" in (message or "")) or ("ë™í™”" in (message or ""))
    wants_feat  = ("í”¼ì³" in (message or "")) or ("íŠ¹ì§•" in (message or "")) or ("feature" in msg_l)

    # í‚¤ì›Œë“œê°€ theme/feature ê°’ê³¼ ë§¤ì¹­ë˜ë©´ ìë™ ë…¸ì¶œ
    if not df.empty and q and q.get("keywords"):
        kw = q["keywords"]
        if themes:
            vals = df[themes].fillna("").astype(str).agg(" ".join, axis=1)
            if any(vals.str.contains(re.escape(t), case=False, na=False).any() for t in kw):
                wants_theme = True
        if feats:
            valsf = df[feats].fillna("").astype(str).agg(" ".join, axis=1)
            if any(valsf.str.contains(re.escape(t), case=False, na=False).any() for t in kw):
                wants_feat = True

    cols = []
    if idcol: cols.append(idcol)
    elif namecol: cols.append(namecol)
    if typecol: cols.append(typecol)  # lines/ways

    if wants_rtp and rtp_col: cols.append(rtp_col)
    if wants_hit and hit_col: cols.append(hit_col)
    if wants_vol and vola_col: cols.append(vola_col)
    if wants_lines:
        if line_col: cols.append(line_col)
        elif ways_col: cols.append(ways_col)
    if wants_size:
        cols.append(size_col if size_col else "_grid")
    if wants_theme: cols += themes
    if wants_feat:  cols += feats

    # ê¸°ë³¸ ìš”ì•½ ì»¬ëŸ¼ ë³´ì¶©
    if len(cols) <= 2:
        for c in [rtp_col, vola_col, hit_col, (line_col or ways_col), (size_col or "_grid")]:
            if c and c not in cols and (c in df.columns or c == "_grid"):
                cols.append(c)

    # ì‹¤ì œ ì¡´ì¬ë§Œ + ì¤‘ë³µ ì œê±°
    seen, final_cols = set(), []
    for c in cols:
        if c and (c == "_grid" or c in df.columns) and c not in seen:
            seen.add(c); final_cols.append(c)

    rename = {
        (idcol or ""): "game_id" if idcol else "ê²Œì„ëª…",
        (namecol or ""): "ê²Œì„ëª…",
        (typecol or ""): "type",           # lines/ways
        (rtp_col or ""): "rtp",
        (vola_col or ""): "volatility",
        (hit_col or ""): "hit_rate",
        (line_col or ""): "line",
        (ways_col or ""): "ways",
        (size_col or ""): "size",
        "_grid": "size",
    }
    out = df.loc[:, [c for c in final_cols if c != "_grid"]].copy()
    if "_grid" in final_cols and "_grid" in df.columns and "size" not in out.columns:
        out.insert(len(out.columns), "size", df["_grid"])
    out = out.rename(columns={k:v for k,v in rename.items() if k in out.columns})
    return out

def build_display_ext(df: pd.DataFrame, S, message: str, q=None):
    idcol   = S["id"] or S["name"]
    namecol = S["name"]
    extcol  = S["ext_type"]  # rgs/sng
    maker   = S["maker"]
    line_col= S["lines"]
    size_col= S["size"]

    themes = [c for c in (S.get("themes") or []) if c in df.columns]
    feats  = [c for c in (S.get("features") or []) if c in df.columns]

    msg_l = (message or "").lower()
    wants_lines = (re.search(r"(ë¼ì¸|lines?)", message or "", flags=re.I) is not None) or (q and q.get("lines"))
    wants_size  = ("ì‚¬ì´ì¦ˆ" in (message or "")) or (re.search(SIZEP, message or "") is not None) or (q and q.get("size"))
    wants_theme = ("í…Œë§ˆ" in (message or "")) or ("ë™í™”" in (message or ""))
    wants_feat  = ("í”¼ì³" in (message or "")) or ("íŠ¹ì§•" in (message or "")) or ("feature" in msg_l)

    cols = []
    if idcol: cols.append(idcol)
    if extcol: cols.append(extcol)     # rgs/sng
    if maker:  cols.append(maker)      # ì œì‘ì‚¬/íšŒì‚¬
    if wants_lines and line_col: cols.append(line_col)
    if wants_size:
        cols.append(size_col if size_col else "_grid")
    if wants_theme: cols += themes
    if wants_feat:  cols += feats

    # ê¸°ë³¸ ë³´ì¶©
    if len(cols) <= 2:
        for c in [line_col, (size_col or "_grid")]:
            if c and c not in cols and (c in df.columns or c == "_grid"):
                cols.append(c)

    # dedupe
    seen, final_cols = set(), []
    for c in cols:
        if c and (c == "_grid" or c in df.columns) and c not in seen:
            seen.add(c); final_cols.append(c)

    rename = {
        (idcol or ""): "game_id",
        (namecol or ""): "ê²Œì„ëª…",
        (extcol or ""): "ext_type",
        (maker or ""): "maker",
        (line_col or ""): "line",
        (size_col or ""): "size",
        "_grid": "size",
    }
    out = df.loc[:, [c for c in final_cols if c != "_grid"]].copy()
    # ì´ë¦„ ë³´ì¡° ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ë’¤ì— ì¶”ê°€
    if namecol and namecol in df.columns and namecol not in out.columns:
        out.insert(1, "ê²Œì„ëª…", df[namecol])
    if "_grid" in final_cols and "_grid" in df.columns and "size" not in out.columns:
        out.insert(len(out.columns), "size", df["_grid"])
    out = out.rename(columns={k:v for k,v in rename.items() if k in out.columns})
    return out

# ====== ê²€ìƒ‰ ì‹¤í–‰ ======
def run_search(message: str):
    q = parse_query(message)

    # ì™¸ë¶€ ìŠ¬ë¡¯ í”Œë¡œìš°
    if q["external_only"] or q["ext_type"]:
        df_raw = load_df("external")
        df, S = prepare_df_ext(df_raw)

        # rgs/sng í•„ìˆ˜: ì—†ìœ¼ë©´ ê³µì§€ í›„ ë¹ˆ ê²°ê³¼
        if not q["ext_type"]:
            view = pd.DataFrame(columns=["game_id","ext_type","maker","size","line"])
            info = "ì™¸ë¶€ ìŠ¬ë¡¯ì€ rgs ë˜ëŠ” sng íƒ€ì…ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ ê²€ìƒ‰ë©ë‹ˆë‹¤. ì˜ˆ) 'rgs, 5x4', 'sng, 5x3', 'sng íŒ¨ìŠ¤íŠ¸í¬ë ˆë”§'."
            return info, view

        m = pd.Series(True, index=df.index)
        # ext_type
        m &= (df["_ext_type"] == q["ext_type"])
        # size
        m &= filter_size(df, q["size"])
        # ë¼ì¸ ìˆ«ì í•„í„° (ë¼ì¸/ways ê°œë… ì—†ìŒ â†’ line ìˆ«ìë§Œ)
        if "_lines" in df.columns:
            m &= apply_numeric(df, "_lines", q["lines"])
        # í‚¤ì›Œë“œ: name/id/maker/themes/features ì—ì„œ AND ê²€ìƒ‰
        text_cols = []
        for key in ["name","id","maker"]:
            col = S.get(key)
            if col in df.columns: text_cols.append(col)
        for c in (S.get("themes") or []):
            if c in df.columns: text_cols.append(c)
        for c in (S.get("features") or []):
            if c in df.columns: text_cols.append(c)
        m &= keyword_mask_text(df, text_cols, q["keywords"])

        res = df.loc[m].copy()
        # ì •ë ¬: maker, name
        sort_cols = [c for c in [S.get("maker"), S.get("name")] if c in res.columns]
        if sort_cols:
            res = res.sort_values(sort_cols, ascending=[True]*len(sort_cols), na_position="last")

        view = build_display_ext(res, S, message, q=q).head(200).reset_index(drop=True)
        return f"ì´ {len(view)}ê°œ ê²°ê³¼ (ì™¸ë¶€ ìŠ¬ë¡¯: {q['ext_type']})", view

    # ë‚´ë¶€ ìŠ¬ë¡¯ í”Œë¡œìš°(ê¸°ì¡´)
    df_raw = load_df("main")
    df, S = prepare_df_main(df_raw)

    m = pd.Series(True, index=df.index)
    m &= filter_size(df, q["size"])
    if "_rtp" in df.columns:   m &= apply_numeric(df, "_rtp",  q["rtp"])
    if "_vola" in df.columns:  m &= apply_numeric(df, "_vola", q["volatility"])
    if "_hit" in df.columns:   m &= apply_numeric(df, "_hit",  q["hit_rate"])
    if "_lines" in df.columns: m &= apply_numeric(df, "_lines", q["lines"])
    if "_ways"  in df.columns: m &= apply_numeric(df, "_ways",  q["ways"])

    # í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ
    text_cols = []
    for k in ["name", "id", "type", "maker"]:
        if S.get(k) in df.columns:
            text_cols.append(S[k])
    for c in (S.get("themes") or []):
        if c in df.columns: text_cols.append(c)
    for c in (S.get("features") or []):
        if c in df.columns: text_cols.append(c)
    m &= keyword_mask_text(df, text_cols, q["keywords"])
    # ëœë“œì•¤ìœˆ
    m &= df["_lines_txt"].astype(str).str.contains("land&win", na=False) if q["landwin"] else m

    res = df.loc[m].copy()

    # ì •ë ¬: rtp/í¸ì°¨/íˆíŠ¸ìœ¨/ì´ë¦„
    sort_cols = [c for c in ["_rtp","_vola","_hit", S["name"]] if c in res.columns]
    if sort_cols:
        res = res.sort_values(sort_cols, ascending=[False, False, False, True][:len(sort_cols)], na_position="last")

    view = build_display_main(res, S, message, q=q).head(200).reset_index(drop=True)
    info = f"ì´ {len(view)}ê°œ ê²°ê³¼"
    return info, view

# ====== UI ======
def render_history(hist):
    lines = []
    for u, a in hist:
        lines.append(f"**You:** {u}")
        lines.append(f"**Bot:** {a}")
        lines.append("---")
    return "\n".join(lines) if hist else "_ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”._"

with gr.Blocks(css=CUSTOM_CSS, title="Kanana ìŠ¬ë¡¯ ê²€ìƒ‰ â€” ìŠ¬ë¡¯ì„œì¹˜ì™„ì„±1.3-external") as demo:
    gr.Markdown("### Kanana ìŠ¬ë¡¯ ê²€ìƒ‰ â€” ìŠ¬ë¡¯ì„œì¹˜ì™„ì„±1.3-external (GitHub CSV / data ë¸Œëœì¹˜)")

    with gr.Row():
        # ì¢Œì¸¡: íˆìŠ¤í† ë¦¬(ë“œë˜ê·¸/ìŠ¤í¬ë¡¤ ê³ ì •)
        with gr.Column(scale=1, min_width=280):
            gr.Markdown("**ğŸ—’ï¸ ë¡œê·¸ / ê²€ìƒ‰ ê¸°ë¡**")
            history = gr.State([])
            history_md = gr.Markdown(render_history([]), elem_id="history-box")
            clear_btn = gr.Button("ë¡œê·¸ ì§€ìš°ê¸°")

        # ìš°ì¸¡: ê²€ìƒ‰/ê²°ê³¼
        with gr.Column(scale=3):
            query = gr.Textbox(
                placeholder="ì˜ˆ) rgs 5x4 / sng 5x3 / sng íƒ€ì… 5x3 / ì™¸ë¶€ ìŠ¬ë¡¯ íŒ¨ìŠ¤íŠ¸í¬ë ˆë”§ / 25ë¼ì¸ / 243 ways / 5x3 / í¸ì°¨ 11 / rtp 95%",
                label="ì§ˆë¬¸/ì¡°ê±´"
            )
            with gr.Row():
                search_btn  = gr.Button("ê²€ìƒ‰")
                preview_btn = gr.Button("CSV ë¯¸ë¦¬ë³´ê¸°(ë‚´ë¶€)")
                preview_ext = gr.Button("CSV ë¯¸ë¦¬ë³´ê¸°(ì™¸ë¶€)")
                refresh_btn = gr.Button("ë°ì´í„° ìƒˆë¡œê³ ì¹¨")

            status_md = gr.Markdown()
            results_df = gr.Dataframe(label="ê²€ìƒ‰ ê²°ê³¼", interactive=False, height=520, wrap=True)

    # í•¸ë“¤ëŸ¬
    def on_search(msg, hist):
        try:
            info, df = run_search(msg)
        except Exception as e:
            info, df = f"âŒ ì—ëŸ¬: {e}", pd.DataFrame()
        new_hist = (hist or []) + [(msg, info)]
        return "", new_hist, render_history(new_hist), df

    def on_preview():
        try:
            df_raw = load_df("main")
            df, S = prepare_df_main(df_raw)
            preview_cols = build_display_main(df, S, "ë¯¸ë¦¬ë³´ê¸°").head(20).reset_index(drop=True)
            return preview_cols
        except Exception as e:
            return pd.DataFrame({"ì˜¤ë¥˜":[str(e)]})

    def on_preview_ext():
        try:
            df_raw = load_df("external")
            df, S = prepare_df_ext(df_raw)
            preview_cols = build_display_ext(df, S, "ë¯¸ë¦¬ë³´ê¸°").head(20).reset_index(drop=True)
            return preview_cols
        except Exception as e:
            return pd.DataFrame({"ì˜¤ë¥˜":[str(e)]})

    def on_refresh():
        try:
            load_df("main", force=True)
            load_df("external", force=True)
            return "âœ… ìµœì‹  CSVë¡œ ìƒˆë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ë‚´ë¶€/ì™¸ë¶€)"
        except Exception as e:
            return f"âŒ ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨: {e}"

    def on_clear():
        return [], render_history([])

    # ë°”ì¸ë”©
    query.submit(on_search, [query, history], [query, history, history_md, results_df])
    search_btn.click(on_search, [query, history], [query, history, history_md, results_df])
    preview_btn.click(on_preview, None, results_df)
    preview_ext.click(on_preview_ext, None, results_df)
    refresh_btn.click(lambda: on_refresh(), None, status_md)
    clear_btn.click(on_clear, None, [history, history_md])

# ì—”ë“œí¬ì¸íŠ¸ í™œì„±í™”
demo.queue()
if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0",
                server_port=int(os.getenv("PORT", 7860)),
                share=True,
                show_error=True)
